{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP lecture.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOEjcTDWtLAXhp3XVK1G+BV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/analyst-rhie/data-collection-information/blob/main/NLP_lecture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v0KZS220O18"
      },
      "source": [
        "# temsorflow 설치 확인 및 test\n",
        "import tensorflow as tf \n",
        "a = tf.constant([10,10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7p_QAZNa3z7s"
      },
      "source": [
        "### 크롤링 계획 수립\n",
        "* Global\n",
        "  * 상업성/비상업성의 여부와 법적문제검토, 사용 가능 언어와 기술적 구현의 난이도를 고려\n",
        "    * 크롤링 허용/불허용 확인 법 : robots.txt 웹 주소 뒤에 붙여두기\n",
        "* 1. 크롤링 하려는 정보에 대한 정의 (어떤 데이터를 수집할 것인가?)\n",
        "  * 어떠한 주식 데이터가 필요한가?\n",
        "  * 수집해야하는 항목은?\n",
        "  * 어떠한 형식으로 저장함? (excel, csv ...)\n",
        "\n",
        "* 2. 해당 데이터를 수집하기에 가장 적합한 웹 페이지는 무엇인가?\n",
        "  * 네이버 금융\n",
        "  * Yahoo! Finance\n",
        "  * 증권사 HTS\n",
        "\n",
        "* 3. 어떤 기술적 방법으로 접근할 것인가?\n",
        "  * 마우스 클릭 등의 동작이 필요한가?\n",
        "  * 봇 제어 방지 시스템이 필요한가?\n",
        "  * 효과적인 접근 방법은?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7zxo4VpH-b8"
      },
      "source": [
        "## 웹 글 추출법  1. BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qdy8AXE80lmU"
      },
      "source": [
        "# BeatifulSoup 확인\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9aghnOB5ETN"
      },
      "source": [
        "html_txt = '''\n",
        "<html>\n",
        "<body>\n",
        "<h1 id=\"title> 자연어 처리 입문 강의<h1>\n",
        "<p id=\"contents\"> 코드 구현 을 중심 으로 진 행 합 니다. </p>\n",
        "</body>\n",
        "</html>\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKyBfnV77oA5"
      },
      "source": [
        "soup = BeautifulSoup(html_txt, 'lxml') #html 파싱방법보다 lxml 방법이 더 빠르다.\n",
        "#lxml은 별도로 pip install 해야 함."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtUv8bZA7tve"
      },
      "source": [
        "# 뷰티플스푸가 html을 분석한 부분을 보여줌.\n",
        "soup.html.body\n",
        "soup.html.h1\n",
        "soup.html.p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTqvJ4Hq7_u5"
      },
      "source": [
        "# 한개의 요소를 찾을 때\n",
        "soup = BeautifulSoup(html_txt, 'lxml') \n",
        "result = soup.find(element = name) # e.g. soup.find(id='h1')\n",
        "\n",
        "# 여러 개의 요소를 찾을 때 \n",
        "result=soup.find_all(element = name) #e.g.soup.find_all(id='h1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SksGbMTx9Dzk"
      },
      "source": [
        "* 웹 개발자 모드를 실행하기 위해 웹페이지에서 ctrl + shift + i 실행\n",
        "  * 원하는 요소를 찾는 법 : 예를 들어 로그인/회원가입 웹 키를 두고 테스트 한다면 마우스 오른쪽 클릭 후 목록에서 검사를 클릭한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FYL4Gvg88u6"
      },
      "source": [
        "import urllib.request as req"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3zPijr29oQv",
        "outputId": "886abb1a-30a6-4b6a-f158-a34701da6509"
      },
      "source": [
        "#with문은 객체의 라이프사이클을 만들어 생성->출력->소멸 과정을 디자인 할 수 있다.\n",
        "url = \"https://learningspoons.com/\"\n",
        "with req.urlopen(url) as res : # 웹 개발자모드 실행\n",
        "  soup = BeautifulSoup(res, 'lxml') # lxml 로 웹 사이트 구성요소 soup에 저장\n",
        "  results= soup.select('li > a[href=\"https://learningspoons.com/account\"]') # 원하는 조건을 선택해줌.\n",
        "   # A > B 에서 A의 상위요소들 중 B의 하위요소를 선택하겠다는 뜻.(문자열이기 때문에 반드시 띄어쓰기 해줘야함)\n",
        "   # 이때 a[ ] 구조는 a 내 href 로 구성된 하위요소들을 찾는데 사용한다.\n",
        "  for idx, result in enumerate(results):\n",
        "    print(idx, result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 <a class=\"nav-top-link nav-top-not-logged-in is-small\" href=\"https://learningspoons.com/account\">\n",
            "<span>\n",
            "    로그인     / 회원가입  </span>\n",
            "</a>\n",
            "1 <a class=\"account-link-mobile is-small\" href=\"https://learningspoons.com/account\" title=\"내 계정\">\n",
            "<i class=\"icon-user\"></i> </a>\n",
            "2 <a class=\"nav-top-link nav-top-not-logged-in\" href=\"https://learningspoons.com/account\">\n",
            "<span class=\"header-account-title\">\n",
            "    로그인  </span>\n",
            "</a>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jLEf-VlFJUd"
      },
      "source": [
        "* 실제 홈페이지에서 글자 가져와보기\n",
        "  * href위치가 다 다르기 때문에 위에 처럼 가져올 수없음. 이때 공통적인 class를 찾아 가져온다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QK269POXA2kv",
        "outputId": "ec872828-3a81-477c-99b6-eefa6bff12c4"
      },
      "source": [
        "url = \"https://online.learningspoons.com/\"\n",
        "with req.urlopen(url) as res :\n",
        "  soup = BeautifulSoup(res, 'lxml')\n",
        "  results = soup.select('h2[class=\"bb-course-title\"] > a') # h2라는 조건들 중에서 class가 \" ~\"인 요소를 선택하고 a를 최종적으로 선택을 하겠다라는 의미\n",
        "  for result in results :\n",
        "    print(f'강의명:{result.string}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "강의명:처음 만나는 RPA : No코딩 업무 자동화로 진짜 일잘러 되기\n",
            "강의명:고객의 숨은 니즈를 파악하는 유저 리서치 기반 UX 입문\n",
            "강의명:[넷플 pick!] 리액티브 프로그래밍 with 람다(lambda)\n",
            "강의명:완전 쉽게 익히는 R 데이터 분석\n",
            "강의명:[취준생 주목!]코딩테스트를 위한 필수 알고리즘 정복&기출 문제 풀이 with 파이썬\n",
            "강의명:박 회계사에게 배우는 반드시 오를 저평가 주식 발굴 및 가치평가\n",
            "강의명:엑셀 파이낸셜 모델링 설계 및 구현 실무\n",
            "강의명:하루 20분! 코알못을 위한 파이썬 기초 한달 완성\n",
            "강의명:초보도 퍼포먼스 내는 디지털 마케팅 패키지 : 광고 집행, 데이터 분석, 자격증까지!\n",
            "강의명:엑셀을 활용한 퀀트 투자 전략 입문\n",
            "강의명:[취준생 주목!]코딩테스트를 위한 필수 알고리즘 정복&기출 문제 풀이 with 파이썬\n",
            "강의명:대기업도 반한 템플릿 제작자의 PPT 기초 & 디자인\n",
            "강의명:[100% 환급] 일잘러 마스터 패키지 : 엑셀/업무자동화/데이터분석/영상편집/회계까지\n",
            "강의명:엑셀 VBA를 활용한 업무 자동화\n",
            "강의명:수익모델을 만드는 에어비앤비 창업과 운영\n",
            "강의명:박 회계사에게 배우는 반드시 오를 저평가 주식 발굴 및 가치평가\n",
            "강의명:부동산 개발 및 사업수지 분석 기초\n",
            "강의명:데이터 사이언티스트에게 배우는 파이썬 머신러닝 & 포트폴리오\n",
            "강의명:고객의 숨은 니즈를 파악하는 유저 리서치 기반 UX 입문\n",
            "강의명:어도비 디자인/영상편집 마스터 패키지\n",
            "강의명:NLP 첫걸음! 자연어 처리 입문 완벽 가이드\n",
            "강의명:펀드매니저에게 배우는 팩터 인베스팅\n",
            "강의명:엑셀을 활용한 자산배분 퀀트 투자 전략\n",
            "강의명:[엑셀 끝판왕] 함수, 데이터 분석, 자동화까지! 엑셀 마스터 패키지\n",
            "강의명:회계 왕초보 탈출반\n",
            "강의명:주식거래 시스템 구축 저자와 함께하는 북콘서트\n",
            "강의명:엑셀 파이낸셜 모델링 설계 및 구현 실무\n",
            "강의명:완전 쉽게 익히는 R 데이터 분석\n",
            "강의명:파이썬 금융 프로그래밍 온라인 부트캠프\n",
            "강의명:월 매출 5억의 운영자가 알려주는 스마트스토어 실전 마케팅 전략\n",
            "강의명:비전공자/입문자를 위한 AI 비즈니스 이해 및 케이스 스터디\n",
            "강의명:엑셀로 만드는 상업용 부동산 : 사업타당성 분석 모델 실습\n",
            "강의명:영상편집의 금손이 되는 프리미어/애프터이펙트 실전\n",
            "강의명:대체투자 운용실무 : 물류 부동산 개발 및 Market Trend\n",
            "강의명:데이터 분석가 취업! 파이썬 머신러닝 포트폴리오 패키지\n",
            "강의명:업무 효율성 향상과 스마트 워크를 위한 노션/슬랙 패키지\n",
            "강의명:입문자를 위한 파이썬 데이터분석 & 시각화\n",
            "강의명:실무에서 바로 써먹는 포토샵/일러스트/인디자인\n",
            "강의명:부장님께 사랑받는 신입사원 필수 스킬! 실무엑셀 + PPT\n",
            "강의명:애자일 방법론\n",
            "강의명:초기 투자자를 위한 비상장주식 및 엔젤투자의 이해\n",
            "강의명:주린이를 위한 한국/미국 주식 매수의 정석 : 매수 타이밍 포착법\n",
            "강의명:부동산 투잡 첫걸음 : 소액으로 시작하는 부동산 투자 입문반\n",
            "강의명:디자인 씽킹 방법론\n",
            "강의명:처음 만나는 RPA : No코딩 업무 자동화로 진짜 일잘러 되기\n",
            "강의명:부동산 투잡/창업 패키지 Airbnb + 쉐어하우스\n",
            "강의명:마케터/ 기획자/ 1인 사업가들 주목! 포토샵으로 끝장내는 SNS 콘텐츠 제작\n",
            "강의명:주식투자 입문: 기본적 분석 & 기술적 분석\n",
            "강의명:파이썬으로 배우는 금융공학/퀀트\n",
            "강의명:퀀트 투자 마스터 패키지\n",
            "강의명:칼퇴를 부르는 필수 업무 스킬, 실무 엑셀!\n",
            "강의명:돈 버는 투자자가 되는 재무제표 분석 기초 & 실전\n",
            "강의명:[패키지] 부동산 개발 및 PF 실무 마스터 : 호텔/오피스/물류/주택\n",
            "강의명:쉽게 따라하는 프리미어 프로 : 유튜브 영상편집 마스터\n",
            "강의명:월급 두 번 받는 직장인 되기! 부동산 재테크 패키지\n",
            "강의명:[넷플 pick!] 리액티브 프로그래밍 with 람다(lambda)\n",
            "강의명:하루 20분! 코알못을 위한 파이썬 기초 한달 완성\n",
            "강의명:집 없이도 월세 받는 쉐어하우스 재테크\n",
            "강의명:파이썬을 활용한 주식 자동매매 프로그램 만들기\n",
            "강의명:박 회계사처럼 공모주 투자하기 : 공모주 투자의 모든 것\n"
          ]
        }
      ]
    }
  ]
}